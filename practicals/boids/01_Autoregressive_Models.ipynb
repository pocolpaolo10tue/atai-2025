{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive Models\n",
    "\n",
    "In this practical, we'll go over the following topics:\n",
    "- Autoregressive models and when to use them\n",
    "- Implementing equivariances in Autoregressive GNNs\n",
    "- Evaluating scientific AI models\n",
    "\n",
    "But first, a short introduction on the dataset used for this practical.\n",
    "\n",
    "![Boids gif](figures/boids.gif)\n",
    "\n",
    "## Boids (by Craig Reynolds)\n",
    "\n",
    "The Boids algorithm, developed by Craig Reynolds [2], aims to replicate the behavior of flocking birds. \n",
    "\n",
    "The simplest setting, used in this practical, follows three simple rules:\n",
    "\n",
    "1. Separation: Each boid should steer away from crowding local flockmates (avoiding collisions)\n",
    "2. Alignment: Each boid should steer towards the average heading of local flockmates\n",
    "3. Cohesion: Each boid should steer towards the average position of local flockmates\n",
    "\n",
    "With some parameter tuning, these rules allow for some surprisingly realistic behavior. A gif of one of the simulations is shown above.\n",
    "\n",
    "### Implementation details\n",
    "\n",
    "Our dataset consists of 1000 samples of Boids simulations. Each simulation has 25 Boids and continues for 1000 timesteps. The Boids fly around in a 2D grid of 1000 x 1000 units.\n",
    "\n",
    "In our simulations, Boids steer away from eachother (Separation) if they are within 16 units of eachother. Boids steer towards the average heading/position of all (local) flockmates within 40 units.*\n",
    "Finally, we use periodic boundary conditions; Boids cannot leave the screen, they re-enter on the other side (pacman style).\n",
    "\n",
    "* We use Euclidean distance (with PBC) here to compute the distance between boids. For a more detailed explanation, visit [The minimum image convention](https://en.wikibooks.org/wiki/Molecular_Simulation/Periodic_Boundary_Conditions) section of the wikibooks page on PBC.\n",
    "\n",
    "## Problem setting\n",
    "\n",
    "Boids simulations feature complex interactions between multiple actors (nodes). The simulation can be chaotic and very sensitive to initial conditions. \n",
    "\n",
    "\n",
    "This makes it an interesting playground for the models/frameworks discussed in the course. In this practical, we will implement an AR model from scratch, then gradually introduce equivariances and training/evaluation methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "First let's look at the data structure, and some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = [np.load(f\"../../data/boids/raw/{f}\") for f in os.listdir(\"../../data/boids/raw\") if f.endswith(\".npy\")]\n",
    "print(len(trajectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Single trajectory shape:\")\n",
    "print(trajectories[0].shape)\n",
    "print(\"The axes and their cardinalities; (Timesteps:1000, Boids:25, (Position X, Position Y, Velocity x, Velocity y):4)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the mean, std, min and max of the boid positions, velocities\n",
    "positions = np.array([t[:, :, :2] for t in trajectories])\n",
    "velocities = np.array([t[:, :, 2:] for t in trajectories])\n",
    "\n",
    "print(\"Position mean, std, min, max:\")\n",
    "# Round to 2 decimal places\n",
    "print(round(np.mean(positions),2), round(np.std(positions),2), round(np.min(positions), 2), round(np.max(positions), 2))\n",
    "print()\n",
    "print(\"Velocity mean, std, min, max:\")\n",
    "# Round to 2 decimal places\n",
    "print(round(np.mean(velocities),2), round(np.std(velocities),2), round(np.min(velocities), 2), round(np.max(velocities), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(trajectory, timestep):\n",
    "    fig, ax = plt.subplots()\n",
    "    # Plot dots for the boids\n",
    "    ax.scatter(trajectory[timestep, :, 0], trajectory[timestep, :, 1])\n",
    "    # plot the boid velocities as arrows\n",
    "    for i in range(trajectory.shape[1]):\n",
    "        # NOTE: The arrows are made larger for effect\n",
    "        ax.arrow(trajectory[timestep, i, 0], trajectory[timestep, i, 1], trajectory[timestep, i, 2]*5, trajectory[timestep, i, 3]*5)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot timesteps 0, 250, 500, 750, 999 for the first trajectory\n",
    "trajectory = trajectories[0]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for i, t in enumerate([0, 250, 500, 750, 999]):\n",
    "    axs[i].set_title(f\"Timestep {t}\")\n",
    "    # Plot dots for the boids\n",
    "    axs[i].scatter(trajectory[t, :, 0], trajectory[t, :, 1])\n",
    "    # plot the boid velocities as arrows\n",
    "    for j in range(trajectory.shape[1]):\n",
    "        # NOTE: The arrows are made larger for effect\n",
    "        axs[i].arrow(trajectory[t, j, 0], trajectory[t, j, 1], trajectory[t, j, 2]*5, trajectory[t, j, 3]*5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, you can see that after some warmup time, the boids start to form flocks. Flocking behavior is a form of inter-node communication, which we will come back to again later.\n",
    "\n",
    "Thinking back to the Geometric Deep Learning framework, we can identify the following symmetries in the data:\n",
    "\n",
    "- The boids are equivariant to permutations, ie it does not matter in which order we compute the update rules for the boids.\n",
    "- Local flocks of boids are equivariant to translation, rotation and reflection. \n",
    "\n",
    "Following these symmetries, it makes sense to model the boids using a Graph Neural Network (GNN). Specifically, since we are dealing with inter-node communication, we will be implementing a Message Passing GNN here.\n",
    "\n",
    "But first, we create a `torch_geometric` InMemoryDataset object, to model the data as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR_Boids_Dataset(InMemoryDataset):\n",
    "    def __init__(self, raw_data_path, processed_data_path, root=None, transform=None, pre_transform=None, post_transform=None, solution_idx_range=(0, 25), timesteps=1000, processed_file_name=\"AR1_Boids.pt\"):\n",
    "        self.raw_data_path = raw_data_path\n",
    "        self.processed_data_path = processed_data_path\n",
    "        self.solution_idx_range = solution_idx_range\n",
    "        self.timesteps = timesteps\n",
    "        self.processed_file_name = processed_file_name\n",
    "        self.pre_transform = pre_transform\n",
    "        self.transform = transform\n",
    "        self.post_transform = post_transform\n",
    "        super(AR_Boids_Dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [self.processed_file_name]\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [pfn for pfn in os.listdir(self.raw_data_path) if (self.solution_idx_range[0] <= int(pfn.split(\"_\")[-1][:-4]) < self.solution_idx_range[1])]\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.timesteps - 1) * (self.solution_idx_range[1] - self.solution_idx_range[0])\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        for idx, raw_path in enumerate(self.raw_file_names):\n",
    "            trajectory = np.load(self.raw_data_path + raw_path)\n",
    "\n",
    "            if self.transform is not None:\n",
    "                trajectory = self.transform(trajectory)\n",
    "\n",
    "            for t in range(trajectory.shape[0] - 1):\n",
    "                x = torch.tensor(trajectory[t], dtype=torch.float)\n",
    "                y_temp = torch.tensor(trajectory[t+1], dtype=torch.float)\n",
    "                # y_temp is (position x, position y, velocity x, velocity y) for the next timestep\n",
    "                # However, we want delta position and delta velocity\n",
    "                # Luckily, the delta poisition is just the velocity from the next timestep, and the delta velocity is the acceleration\n",
    "                # So we can just take the last two elements of y to get the delta velocity\n",
    "                # First we copy the last two columns of y to the first two columns of y\n",
    "                y = y_temp.clone()\n",
    "                y[:, :2] = y_temp[:, 2:]\n",
    "                # Then we calculate the acceleration\n",
    "                y[:, 2:] = y_temp[:, 2:] - x[:, 2:]    # (V_x ^ (t+1), V_y ^ (t+1), a_x, a_y)\n",
    "\n",
    "                # fully connected graph\n",
    "                edge_index = torch.tensor([[i, j] for i in range(trajectory.shape[1]) for j in range(trajectory.shape[1]) if i != j], dtype=torch.long).t().contiguous()\n",
    "    \n",
    "                if self.post_transform is not None:\n",
    "                    data = self.post_transform(data)\n",
    "                \n",
    "                data = Data(x=x, y=y, edge_index=edge_index)\n",
    "                data_list.append(data)\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_data_path+self.processed_file_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.get(idx)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}({len(self)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AR_Boids_Dataset(raw_data_path=\"../../data/boids/raw/\", processed_data_path=\"../../data/boids/processed/\", root=\"../../data/boids/\", solution_idx_range=(0, 15), timesteps=1000, processed_file_name=\"AR1_Boids.pt\")\n",
    "validation_dataset = AR_Boids_Dataset(raw_data_path=\"../../data/boids/raw/\", processed_data_path=\"../../data/boids/processed/\", root=\"../../data/boids/\", solution_idx_range=(16, 25), timesteps=1000, processed_file_name=\"AR1_VAL_Boids.pt\")\n",
    "\n",
    "print(train_dataset)\n",
    "print(validation_dataset)\n",
    "\n",
    "\n",
    "data_0 = train_dataset[0]\n",
    "print(data_0)\n",
    "print(data_0.keys)\n",
    "print(\"Pos x, Pos y, Vel x, Vel y\")\n",
    "print(data_0.x[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Models\n",
    "In general, when dealing with simulations spanning multiple timesteps, we can define the learning problem as follows.\n",
    "\n",
    "Let $X^{0:T-1}$ denote the states spanning across timesteps $t=0$ through $t=T-1$. Given the initial state $X^0$, our goal is to accurately predict the future states $X^{1:T-1}$. In the probabilistic case, we want to learn a model with parameters $\\theta$ for the probability distribution $P_\\theta(X^{1:T-1}|X^0)$.*\n",
    "\n",
    "In some systems, such as in the Boids setting, the next state X^{t+1} is only dependent on the current state X^t. Such systems are memoryless, and are often said to be _Markovian_. The Markov property allows us to rewrite the learning task to $P_\\theta(X^{1:T-1}|X^0) = \\prod_{t=0}^{T-2} P_\\theta(X^{t+1} | X^t)$\n",
    "\n",
    "Here, $P_\\theta(X^{t+1} | X^t)$ is the _Autoregressive model_ - literally meaning it is used to autoregressively construct the full trajectory of the system. Note that this model is autoregressive in time; not space.\n",
    "\n",
    "*: In this practical, we will not be building a probabilistic model. So instead of parameterizing a distribution, we learn a function $f_\\theta: X^t \\rarr X^{t+1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregressive set model\n",
    "\n",
    "Below, we create the simplest AR model for the Boids system; a fully connected GNN (essentially a set model).\n",
    "\n",
    "Given a fully connected graph $X^t$, representing the Boids system at time $t$; it learns to predict the next state of the system $X^{t+1}$.\n",
    "\n",
    "Note here that we use all features from the dataset as node features. This causes the model to not be equivariant to some group actions, that are relevant in the Boids setting.\n",
    "\n",
    "---\n",
    "\n",
    "Tick the equivariance(s) of this model:\n",
    "\n",
    "- <input\n",
    "      type=\"checkbox\"\n",
    "      id=\"eq0\"\n",
    "      name=\"perm\"\n",
    "      value=\"perm\" />\n",
    "    <label for=\"eq1\">Permutational Equivariance</label>\n",
    "\n",
    "- <input\n",
    "      type=\"checkbox\"\n",
    "      id=\"eq1\"\n",
    "      name=\"space\"\n",
    "      value=\"space\" />\n",
    "    <label for=\"eq1\">Space Translation Equivariance</label>\n",
    "\n",
    "- <input\n",
    "      type=\"checkbox\"\n",
    "      id=\"eq2\"\n",
    "      name=\"time\"\n",
    "      value=\"time\" />\n",
    "    <label for=\"eq2\">Time Translation Equivariance</label>\n",
    "\n",
    "- <input\n",
    "      type=\"checkbox\"\n",
    "      id=\"eq3\"\n",
    "      name=\"rot\"\n",
    "      value=\"rot\" />\n",
    "    <label for=\"eq3\">Rotation/Reflection Equivariance</label>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AR_Set_Model(torch.nn.Module):\n",
    "    def __init__(self, node_dim=4, emb_dim=16, out_dim=4):\n",
    "        super(AR_Set_Model, self).__init__()\n",
    "        self.node_embedding = torch.nn.Linear(node_dim, emb_dim)\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(emb_dim, emb_dim)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(emb_dim, out_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.node_embedding(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_dataset, validation_dataset, batch_size=1, lr=0.0001, epochs=100, loss_fn=torch.nn.MSELoss(), model_name= \"01-AR-Set-Model.pt\"):\n",
    "        \"\"\"\n",
    "        Simple Trainer class to train a PyTorch (geometric) model on a dataset.\n",
    "\n",
    "        Args:\n",
    "            model: PyTorch model to train\n",
    "            train_dataset: PyTorch dataset to train on\n",
    "            validation_dataset: PyTorch dataset to validate on\n",
    "            batch_size: Batch size for training\n",
    "            lr: Learning rate\n",
    "            epochs: Number of epochs to train for\n",
    "            loss_fn: Loss function to use\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.validation_dataset = validation_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(\"Using device:\", self.device)\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        self.train_loader = self.make_data_loader(self.train_dataset)\n",
    "        self.validation_loader = self.make_data_loader(self.validation_dataset, shuffle=False)\n",
    "\n",
    "    def make_data_loader(self, dataset, shuffle=True):\n",
    "        return DataLoader(dataset, batch_size=self.batch_size, shuffle=shuffle)\n",
    "\n",
    "    def train_loop(self):\n",
    "        \"\"\"\n",
    "        Train loop for the model\n",
    "        \"\"\"\n",
    "        best_model_loss = np.inf\n",
    "        for epoch in range(self.epochs):\n",
    "            # Train the model\n",
    "            self.model.train()\n",
    "            mean_train_loss = 0\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "                data = self.train_dataset[i].to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(data)\n",
    "                loss = self.loss_fn(out, data.y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                mean_train_loss += loss.item()\n",
    "            mean_train_loss /= i\n",
    "            \n",
    "            # Validate the model\n",
    "            self.model.eval()\n",
    "            mean_val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(self.validation_loader):\n",
    "                    data = self.validation_dataset[i].to(self.device)\n",
    "                    out = self.model(data)\n",
    "                    loss = self.loss_fn(out, data.y)\n",
    "                    mean_val_loss += loss.item()\n",
    "                mean_val_loss /= i\n",
    "\n",
    "            if mean_val_loss < best_model_loss:\n",
    "                best_model_loss = mean_val_loss\n",
    "                torch.save(self.model.state_dict(), f\"../../models/{self.model_name}\")\n",
    "            \n",
    "            print(f\"Epoch {epoch}, Mean Train Loss: {mean_train_loss}, Mean Validation Loss: {mean_val_loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AR_Set_Model(emb_dim=64)\n",
    "trainer = Trainer(model, train_dataset, validation_dataset, batch_size=8, loss_fn=torch.nn.MSELoss(), epochs=100, model_name=\"01-AR-Set-Model.pt\")\n",
    "trainer.train_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Implementing rollout code\n",
    "\n",
    "We have a working model now to predict $\\hat{X}^{t+1}$ given $X^t$. However, we of course want to be able to generate trajectories longer than one step (ie for i steps: $\\hat{X}^{t+1:t+i}$), given $X^t$.\n",
    "\n",
    "We sometimes call this a `rollout` - essentially a multi-step prediction.\n",
    "\n",
    "Q1: Complete the method below, which generates a rollout of `timesteps` steps, for a given model `model`, and dataset `dataset` *.\n",
    "\n",
    "HINT: What should happen if the position $x_i, y_i$ of boid $i$ are predicted to move $dx_i, dy_i$, such that $x_i + dx_i > \\text{width}$ or $y_i + dy_i > \\text{height}$?\n",
    "\n",
    "*: If you check the cell below the next cell, we already made a dataset for you that only contains initial positions :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ar_set_model_rollouts(model, dataset, timesteps=1000, device='cuda', mode=\"residual\", width = 1000, height = 1000):\n",
    "    \"\"\"\n",
    "    Predict the rollouts of the model on the dataset starting from the idx\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        dataset: PyTorch dataset\n",
    "        timesteps: Number of timesteps to predict\n",
    "        device: Device to run the model on\n",
    "        mode: \"residual\" or \"direct\"\n",
    "        - In the solution above, we used the \"residual\" mode, where the model predicts the change in position and change in velocity\n",
    "        - In the \"direct\" mode, the model predicts the position and velocity directly (if you do not intend to use this mode, you can ignore this argument)\n",
    "        width: Width of the PBC box\n",
    "        height: Height of the PBC box\n",
    "    Returns:\n",
    "        rollouts: Rollouts of the model on the dataset\n",
    "        - Should be a torch tensor of shape (Batch, Timesteps, Boids, Node_dim)\n",
    "    \"\"\"\n",
    "    rollouts = torch.empty((len(dataset), timesteps, dataset[0].x.shape[0], dataset[0].x.shape[1]), device=device)\n",
    "    print(rollouts.shape)\n",
    "\n",
    "    # ~ ^ ~ ^ ~ ^ ~ ^ ~ ^ ~ ^\n",
    "    #     Your code here\n",
    "    # ~ ^ ~ ^ ~ ^ ~ ^ ~ ^ ~ ^\n",
    "\n",
    "    \n",
    "    return rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_01(data):\n",
    "    return data[0:2, :, :]\n",
    "\n",
    "initial_states_validation_dataset = AR_Boids_Dataset(\n",
    "    raw_data_path=\"../../data/boids/raw/\", \n",
    "    processed_data_path=\"../../data/boids/processed/\", \n",
    "    root=\"../../data/boids/\", \n",
    "    solution_idx_range=(16, 25), \n",
    "    timesteps=2, \n",
    "    processed_file_name=\"AR1_VAL_init.pt\",\n",
    "    transform=keep_01\n",
    "    )\n",
    "\n",
    "ar_set_model = AR_Set_Model(emb_dim=64)\n",
    "ar_set_model.load_state_dict(torch.load(\"../../models/01-AR-Set-Model.pt\"))\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ar_set_model.to(device)\n",
    "ar_set_model.eval()\n",
    "\n",
    "ar_set_model_rollout = compute_ar_set_model_rollouts(ar_set_model, initial_states_validation_dataset, timesteps=1000, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll evaluate these rollouts later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick recap on equivariances\n",
    "\n",
    "<img src=\"figures/boids-translational-equivariance.png\" alt=\"drawing\" width=\"250\" style=\"background-color: white; padding: 50px;\"/>\n",
    "<img src=\"figures/boids-rotational-equivariance.png\" alt=\"drawing\" width=\"250\" style=\"background-color: white; padding: 50px;\"/>\n",
    "\n",
    "The figures above show the equivariances of the Boids system. The system is equivariant to all E(n) transformations; translation,\n",
    "rotation and reflection.*\n",
    "\n",
    "Formally, we say a function $f: X \\rarr Y$ is _equivariant_ to a group action or transformation $T: X \\rarr X$ if there is an equivalent transformation $S: Y \\rarr Y$ on the output space of the function such that\n",
    "\n",
    "$f(T(x)) = S(f(x))$ for each $x \\in X$\n",
    "\n",
    "We won't go into the formal definitions of each equivariance, but if you're interested you can check out the [E(n) Equivariant Graph Neural Networks](https://arxiv.org/pdf/2102.09844) paper [3], the equivariant model is based on. \n",
    "\n",
    "*: Excluding time translation equivariance, which states that there is no dependence on the time of the system, only the state.\n",
    "\n",
    "*: Also excluding permutational equivariance; the order of the nodes does not matter.\n",
    "\n",
    "## Towards Equivariant AR-GNNs\n",
    "The above model is **not** equivariant to translations in space! This is because we use absolute coordinates as _node features_, which creates a dependence on the absolute coordinate system. Instead, if we do not use the absolute positions as node features - and include the PBC distance as _edge features_ - the predictions will be space translation equivariant.\n",
    "\n",
    "Let's implement this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we were not using the fact that boids only affect eachother within a certain radius, since we used a fully connected graph without edge weights.\n",
    "\n",
    "Before blindly jumping into the new dataset code, let's investigate this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot timesteps 0, 250, 500, 750, 999 for the first trajectory\n",
    "trajectory = trajectories[0]\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 4))\n",
    "fig.suptitle(\"Boids with radius of effect\")\n",
    "radius = 40\n",
    "\n",
    "for i, t in enumerate([0, 250, 500, 750, 999]):\n",
    "    axs[i].set_title(f\"Timestep {t}\")\n",
    "    # Plot dots for the boids\n",
    "    axs[i].scatter(trajectory[t, :, 0], trajectory[t, :, 1])\n",
    "    # Draw a red circle around each boid to indicate the radius\n",
    "    for j in range(trajectory.shape[1]):\n",
    "        circle = plt.Circle((trajectory[t, j, 0], trajectory[t, j, 1]), radius, color='r', fill=False)\n",
    "        axs[i].add_artist(circle)\n",
    "    # plot the boid velocities as arrows\n",
    "    for j in range(trajectory.shape[1]):\n",
    "        # NOTE: The arrows are made larger for effect\n",
    "        axs[i].arrow(trajectory[t, j, 0], trajectory[t, j, 1], trajectory[t, j, 2]*5, trajectory[t, j, 3]*5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 E(n) Equivariant Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Satorras, Hoogeboom, Welling's paper [3] with the same name, they introduce a relatively simple model that is equivariant to E(n) transformations. \n",
    "You can check the official [implementation](https://github.com/vgsatorras/egnn).\n",
    "implement the E(n)-Equivariant Graph Neural Networks (EGNN) model from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    " # TODO: TODO: TODO: TODO: TODO:\n",
    "        \"\"\"\n",
    "        Your code goes here\n",
    "        \n",
    "        \"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Push-forward training\n",
    "\n",
    "Implement the push-forward training mechanism for the AR-Set-Model and the EGNN developed in Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push-forward for AR_Set_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    " # TODO: TODO: TODO: TODO: TODO:\n",
    "        \"\"\"\n",
    "        Your code goes here\n",
    "        \n",
    "        \"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push-forward for EGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    " # TODO: TODO: TODO: TODO: TODO:\n",
    "        \"\"\"\n",
    "        Your code goes here\n",
    "        \n",
    "        \"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating scientific AI models\n",
    "\n",
    "The Boids simulations are very sensitive to changes in the initial state. Slight changes in the initial state can lead to drastically different final states. Similarly, emulations (the neural network predictions) can accumulate errors very quickly.\n",
    "\n",
    "Using MSE to compare models to the ground truth or to each other here does not account for this error accumulation. As a result, a likely generated/predicted trajectory can have high MSE.\n",
    "\n",
    "Luckily for us, there are usually better ways to evaluate models! When working in an interdisciplinary group, the physics wizards will propose a metric that should hold true even when trajectories diverge, or our predictions suffer from accumulating errors.\n",
    "\n",
    "In the Boids setting, we can investigate the distribution of velocities, since these should (hopefully) remain invariant even under diverging trajectories / error accumulation.\n",
    "\n",
    "If we plot them visually, we want to investigate how different the predicted velocity distributions are from the ground truth velocity distributions. However, since we have to investigate the distributions for each timestep, let's use the Kullback-Leibler Divergence ($D_\\text{KL}$) metric to measure the difference. For two distributions $P$ and $Q$, it is defined as follows:\n",
    "\n",
    "\n",
    "$D_\\text{KL}(P||Q) = \\int p(x) \\ln \\frac{p(x)}{q(x)} \\text{d} x $\n",
    "\n",
    "\n",
    "![KL Divergence](https://hugocisneros.com/ox-hugo/forwardvsreversedKL.jpg)\n",
    "\n",
    "\n",
    "The $D_\\text{KL}$ between two distributions $P$ and $Q$ is asymmetric, meaning $D_\\text{KL}(P||Q) \\neq D_\\text{KL}(Q||P)$, as illustrated above. \n",
    "\n",
    "Since we care more whether the predicted distribution $Q$ fits under the ground truth distribution $P$, we will use the reverse KL: $D_\\text{KL}(Q||P)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(dist1, dist2):\n",
    "    \"\"\"\n",
    "    Compare two distributions by computing the KL divergence\n",
    "\n",
    "    Args:\n",
    "        dist1: torch.distributions.Distribution\n",
    "        dist2: torch.distributions.Distribution\n",
    "    \"\"\"\n",
    "    kl = torch.distributions.kl_divergence(dist1, dist2)\n",
    "    return kl\n",
    "\n",
    "def compute_distribution_per_timestep(data, timesteps):\n",
    "    \"\"\"\n",
    "    Compute the distribution of the data per timestep\n",
    "\n",
    "    Args:\n",
    "        data: torch.Tensor of shape (T, N, 4)\n",
    "        timesteps: int, number of timesteps to compute the distribution for\n",
    "\n",
    "    Returns:\n",
    "        list of torch.distributions.Normal\n",
    "    \"\"\"\n",
    "    distributions = []\n",
    "    for t in range(timesteps):\n",
    "        # Compute the mean and std of the data\n",
    "        mean = data[:, t, :, :].mean()\n",
    "        std = data[:, t, :, :].std()\n",
    "        dist = torch.distributions.Normal(mean, std)\n",
    "        distributions.append(dist)\n",
    "    return distributions\n",
    "\n",
    "def compute_mean_kl_divergence(data, distributions):\n",
    "    \"\"\"\n",
    "    Compute the mean KL divergence between the data and the distributions\n",
    "\n",
    "    Args:\n",
    "        data: torch.Tensor of shape (T, N, 4)\n",
    "        distributions: list of torch.distributions.Normal\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    kl_divergences = []\n",
    "    for t in range(data.shape[0]):\n",
    "        kl = compare_distributions(distributions[t], data[t, :, :])\n",
    "        kl_divergences.append(kl)\n",
    "    return torch.tensor(kl_divergences).mean()\n",
    "\n",
    "def plot_kl_divergence(distributions1, distributions2, title=\"KL Divergence between <distributions1> and <distributions2>\"):\n",
    "    \"\"\"\n",
    "    Plot the KL divergence between the data and the distributions\n",
    "\n",
    "    Args:\n",
    "        distributions1: list of torch.distributions.Normal\n",
    "        distributions2: list of torch.distributions.Normal\n",
    "    \"\"\"\n",
    "    kl_divergences = []\n",
    "    for t in range(len(distributions1)):\n",
    "        kl = compare_distributions(distributions1[t], distributions2[t]).cpu().numpy()\n",
    "        kl_divergences.append(kl)\n",
    "\n",
    "\n",
    "    plt.plot(kl_divergences)\n",
    "    plt.xlabel(\"Timestep\")\n",
    "    plt.ylabel(\"KL Divergence\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_files = [pfn for pfn in os.listdir(\"../../data/boids/raw/\") if (16 <= int(pfn.split(\"_\")[-1][:-4]) < 25)]\n",
    "validation_trajectories = [np.load(\"../../data/boids/raw/\" + f) for f in validation_files]\n",
    "validation_trajectories = torch.tensor(validation_trajectories, dtype=torch.float)\n",
    "\n",
    "dists_GT = compute_distribution_per_timestep(validation_trajectories[:,:,:,2:], 1000)\n",
    "dists_AR_set = compute_distribution_per_timestep(ar_set_model_rollout[:,:,:,2:], 1000)\n",
    "plot_kl_divergence(dists_AR_set, dists_GT, title=\"KL Divergence between AR Set Model velocities and the GT velocities per timestep\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_equivariant = compute_distribution_per_timestep(translational_equivariant_model_rollout, 1000)\n",
    "plot_kl_divergence(dists_equivariant, dists_GT, title=\"KL Divergence between Translational Equivariant Model velocities and the GT velocities per timestep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Minartz, K., Poels, Y., Koop, S., & Menkovski, V. (2023). Equivariant Neural Simulators for Stochastic Spatiotemporal Dynamics. https://openreview.net/forum?id=CCVsGbhFdj\n",
    "\n",
    "[2] Reynolds, C. W. (1987) Flocks, Herds, and Schools: A Distributed Behavioral Model, in Computer Graphics, 21(4) (SIGGRAPH '87 Conference Proceedings) pages 25-34.\n",
    "\n",
    "[3] Satorras, V. G., Hoogeboom, E., & Welling, M. (2021, July). E (n) equivariant graph neural networks. In International conference on machine learning (pp. 9323-9332). PMLR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
